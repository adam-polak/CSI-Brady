{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies and imports"
      ],
      "metadata": {
        "id": "B-RMX2zWQsHq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bbH7shqo49AG"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch torchvision Pillow roboflow\n",
        "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
        "import torch\n",
        "from PIL import Image\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load FaceBook's DETR model"
      ],
      "metadata": {
        "id": "Zjgf9n_3Q3b7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained DETR model and processor\n",
        "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
        "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "q_-rI3NQRH8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dataset of OSHA/ANSI violations"
      ],
      "metadata": {
        "id": "tB9C_cmNRLZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating datasets directory\n",
        "!mkdir {HOME}/datasets\n",
        "%cd {HOME}/datasets\n",
        "\n",
        "# Get dataset from Roboflow\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"DVSACmCnjnq3Yb7MimiW\")\n",
        "project = rf.workspace(\"vit16\").project(\"hard-hat-sample-kc3iw\")\n",
        "dataset = project.version(4).download(\"coco\")\n",
        "\n",
        "# Check where dataset is located\n",
        "dataset.location"
      ],
      "metadata": {
        "id": "S0s_3cGgVBYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torchvision\n",
        "\n",
        "_annotations = \"_annotations.coco.json\"\n",
        "train_folder = os.path.join(dataset.location, \"train\")\n",
        "val_folder = os.path.join(dataset.location, \"valid\")\n",
        "test_folder = os.path.join(dataset.location, \"test\")\n",
        "\n",
        "\n",
        "class CocoDetection(torchvision.datasets.CocoDetection):\n",
        "    def __init__(\n",
        "        self,\n",
        "        image_directory_path: str,\n",
        "        processor,\n",
        "        train: bool = True\n",
        "    ):\n",
        "        annotation_file_path = os.path.join(image_directory_path, _annotations)\n",
        "        super(CocoDetection, self).__init__(image_directory_path, annotation_file_path)\n",
        "        self.processor = processor\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        images, annotations = super(CocoDetection, self).__getitem__(idx)\n",
        "        image_id = self.ids[idx]\n",
        "        annotations = {'image_id': image_id, 'annotations': annotations}\n",
        "        encoding = self.processor(images=images, annotations=annotations, return_tensors=\"pt\")\n",
        "        pixel_values = encoding[\"pixel_values\"].squeeze()\n",
        "        target = encoding[\"labels\"][0]\n",
        "\n",
        "        return pixel_values, target\n",
        "\n",
        "\n",
        "train_dataset = CocoDetection(image_directory_path=train_folder, processor=processor, train=True)\n",
        "val_dataset = CocoDetection(image_directory_path=val_folder, processor=processor, train=False)\n",
        "test_dataset = CocoDetection(image_directory_path=test_folder, processor=processor, train=False)\n",
        "\n",
        "print(\"Number of training examples:\", len(train_dataset))\n",
        "print(\"Number of validation examples:\", len(val_dataset))\n",
        "print(\"Number of test examples:\", len(test_dataset))"
      ],
      "metadata": {
        "id": "Fzh3WODjmYCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model"
      ],
      "metadata": {
        "id": "CI_ebmOfjEsD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5tp79Wx17F0T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}